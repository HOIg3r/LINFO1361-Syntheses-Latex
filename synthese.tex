\documentclass[12pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{float}


% Margins
\usepackage[top=1.5cm, left=2cm, right=2cm, bottom=2.0cm]{geometry}
% Colour table cells
\usepackage[table]{xcolor}

% Get larger line spacing in table
\newcommand{\tablespace}{\\[1.25mm]}
\newcommand\Tstrut{\rule{0pt}{2.6ex}}         % = `top' strut
\newcommand\tstrut{\rule{0pt}{2.0ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut

%%%%%%%%%%%%%%%%%
%     Title     %
%%%%%%%%%%%%%%%%%
\title{Synthèse Artificial Inteligence LINFO1115}
\author{Jacques HOGGE}
\date{\today}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

%Introduction
\input{Chap 1}

\newpage

%2.1-2.3
\input{Chap 2}

\newpage

%Solving Problem by searching
\input{Chap 3}

\newpage

%Local Search
\input{Chap 4}

\newpage

\input{Chap 5}

\newpage

%Adversarial Search and Games
\input{Chap 6}

\newpage

%Logical agent
\input{Chap 7}

\newpage

\input{Chap 8}

\newpage

\input{Chap 9}

\newpage

\input{Chap 10}

\newpage


		
			
\section{Learning from exemples}
	\textbf{Learning} : Améliorer la performance des prochaines taches apres avoirs faits des observations. On ne peut pas anticiper toutes les situations possible. Le taches future peuvent changer ...
	
	On se concentre seulement sur les learning problem depuis une collections de input/output, apprendre une fonctions qui prédit l'output pour une nouveau input
	
	\subsection{Feedback}
		3 types de feedback et détermine les 3 types d'apprentissage
		\begin{itemize}
			\item \textbf{Supervised Learning} : l'agent observe les inputs et outputs et apprend une fonctions qui match les inputs et outputs
			\item \textbf{Unsupervised Learning} : l'agent apprend des paternes des inputs meme si aucun output est donnés
			\item \textbf{Reinforcement Learning} : l'agent apprend par une succession de récompese ou de punitions en fonctions des ses actions
			
		\end{itemize}
		
	\subsection{Supervised Learning}
		On donne un ensemble d'entrainemenet $(x_1,y_1), \dots , (x_n, y_n)$
			 où $y_i$ est généra par une $f(x_i)$ inconnues. On découvre une fonction $h$ qui approxime $f$
			
			Pour mesurer la précision de l'hypothèse $h$ on test sur un ensemble de test qui est différent de l'ensemble des test utilsé pour le learning de l'agent.
			Un Hypotheses se généralise bien si elle prédit correctement la valeur de $y$ pour de nouveaux exemple
		\subsubsection{Classification VS. Regression}
			\begin{itemize}
				\item \textbf{Classification} : la valeur de sortie est tirée d'un ensemble fini de valeurs
				\item \textbf{Regression} : L'output est un nombre
			
			\end{itemize}
			
		\subsubsection{Ockam's Razor}
			\begin{figure}[H]
				\centering
				\includegraphics[width=\textwidth]{img/razor.png}
			\end{figure}
			
			On choisis toujours l'hypotheses la plus simple et consistente
			
			On donne plus de priorité aux solutions de degréa 1/2 et moins au plus grand (7/8)
			
			il faut choisir $h*$ qui est le plus problable avec les data donnée
			
			\begin{equation}
				h* = arg \ max_{h\ in H} \ P(h|data)
			\end{equation}
			\begin{equation}
				h* = arg \ max_{h \in H} \ P(data|h).P(h)
			\end{equation}
			
	\subsection{Learning Decision Trees}
		Représente une fonctions qui prend un vecteur de valeur en inputs et retourne une décission (un simple valeur). Il trouve ça décission avec une séquence de teste, car chaque node de l'arbre est un test d'un valeur de l'input et les leaf donne la décision.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.8\textwidth]{img/tree.png}
		\end{figure}
		
		\begin{enumerate}
			\item \textit{Alternate} : Seulement Si il y a un restaurant alternatif a coté
			\item \textit{Bar} : Seulement si le restaurant a un bar confortable
			\item \textit{Fri/Sat} : True vendredi et samedis
			\item \textit{Hungry} : Seulement si on a faim
			\item \textit{Patron} : Combien de personne dans le restaurant (None, Some, Full)
			\item \textit{Price} : Fourchette de prix
			\item \textit{Raining} : Si il pleut dehors
			\item \textit{Reservation} : Si on a fait une réservation
			\item \textit{Type} : le type de restaurant (francais, Thaie, italien, Burger)
			\item \textit{WaitEstimate} : Temps d'attente moyen (0, 10, 10-30, 30-60, >60)
		\end{enumerate}
		
		\begin{equation}
			Goal \Leftrightarrow (Path_1 \lor Path_2 \lor \dots \lor Path_n)
		\end{equation}
		
	\subsection{Decision tree from exemple}
	
		Exemple sont des tuples $(X_i, y)$ où $X_i = x_{i1},\dots,x_{in}$ sont les attributs en inputs et $y$ un boolean
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.8\textwidth]{img/DCFE.png}
		\end{figure}
		
	\subsection{The Decision-Tree-Learning Algorithm}
		On veut le tree le plus petit possible, on peut donc choisir l'attribut le plus important ou alors diviser en sous probleme
		\begin{figure}[H]
			\centering
			\includegraphics[width=.8\textwidth]{img/DTLA.png}
		\end{figure}
		
		Quand on crée un arbre de décission, il y a 4 cas possible :
		\begin{enumerate}
			\item Si tous les exemples sont positif (négatif) alors résultate Yes (No)
			\item Si il y a des positif et négatif, alors choisir le meilleur attribut pour les splits
			
			\item Si il n'y a plus d'exemple qui reste retourner une valeur défault
			\item Si il n'y a plus d'attribut qui reste, mais que les exemples sont positif et négatif, alors les exemple sont incohérents. Return la classification plurielle des exemples restants (vote majoritaire)
		\end{enumerate}
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.8\textwidth]{img/DTLA1.png}
		\end{figure}
		
	\subsection{Entropy}
		Caclule l'incertitude d'une variable random.
		
		\begin{equation}
			H(V) = \sum_{k}P(v_k)\log_2(\cfrac{1}{P(v_k)}) = -\sum_{k}P(v_k).\log_2(P(v_k))
		\end{equation}
		
		ex: piece non truquée (50/50)
		\begin{equation}
			H(Fair) = -(0.5\log_2(0.5) + 0.5\log_2(0.5)) = 1
		\end{equation}
		ex: piece truquée (99/1)
		\begin{equation} 
			H(Unfaire) = -(0.99\log_2(0.99) + 0.01\log_2(0.01)) = 0.08
		\end{equation}
		
		L'entropie d'un boolean random ave une probabilité de True a $q$ (false = $1-q$)
		
		\begin{equation}
			B(q) = -(q.\log_2(q) + (1-q).\log_2(1-q))
		\end{equation}
		
	\subsection{Leaning Curves}
		On split les exemples en un ensemble de training et test. On apprend des hypotheses et on mesure la précision avec l'ensemble des test.
		
		On commence avec un ensemble l'entrainement de 1 que on augmente au fur et a mesure. On peut remarquer que la précission augmente avec un ensemble de trainning plus large. 
		
	\subsection{Ensemble learning}
	
		Générer une collectino/ensemble d'hypothese et combiner leur prédictions. Cela augmente les performance.
		\subsubsection{Bagging}
			\begin{itemize}
				\item On génere $K$ training set avec $N$ exemple
				\item Produit $K$ décision d'algo
				\item Pour un nouvel input
				\begin{itemize}
					\item Predit $k$ hypothese
					\item vote a la majorité
				\end{itemize}
			\end{itemize}
			
		\subsubsection{Random Forest}
			Produit $k$ décision algo sur l'exemple donnée
			
			ça varie en fonction du choix des attribut
			
			A chaque split on fait une restriction random des choix des attributs
			
		\subsubsection{Bootsing}
			Un set d'entrainement avec des poids, chaque exemple associé a un exemple et donc adapte sa méthode d'apprentisage avec les poids.
			
			Génère au debut une hypothese avec un poid de 1, on agmente le poids des exemples mal classé. 
			
			On stop quand on a $k$ hypotheses et on les utilise pour calculer la prediction
\end{document}